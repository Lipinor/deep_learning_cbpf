{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkmTY2Uiw6GT4WgJ0ePdn0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lipinor/deep_learning_cbpf/blob/master/cnn_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDf-hUlcpAqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "5f36f713-f728-4e26-d214-3a682a8236f0"
      },
      "source": [
        "pip install mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mnist\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.5)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA_Fcs5EpKkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n",
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdLiKM7Q3gxR",
        "colab_type": "text"
      },
      "source": [
        "#Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uxa9psOpLC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "a63e1018-f7c9-442b-b0b5-1f964ccd6d8f"
      },
      "source": [
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3472 - accuracy: 0.9007 - val_loss: 0.1830 - val_accuracy: 0.9491\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1560 - accuracy: 0.9559 - val_loss: 0.1297 - val_accuracy: 0.9614\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1164 - accuracy: 0.9668 - val_loss: 0.1156 - val_accuracy: 0.9636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f87947f5668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnpTZWo-8dae",
        "colab_type": "text"
      },
      "source": [
        "#Using the model\n",
        "Let's try to make some predicitions with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVGTrxtE8fnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "91d6fc7f-6f2f-4fdb-c024-5622e8511e8e"
      },
      "source": [
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "print(np.argmax(predictions, axis=1))\n",
        "\n",
        "print(test_labels[:5]) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_9kx9I_8CD_",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to make some changes in the model to see what happens. We begin by adding an extra convolutional layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvaPlfWW7rdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "3cc784df-f41d-4104-84ee-861c963934aa"
      },
      "source": [
        "model_layers = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  Conv2D(num_filters, filter_size),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_layers.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_layers.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2796 - accuracy: 0.9181 - val_loss: 0.1287 - val_accuracy: 0.9598\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1055 - accuracy: 0.9679 - val_loss: 0.0789 - val_accuracy: 0.9754\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0786 - accuracy: 0.9761 - val_loss: 0.0755 - val_accuracy: 0.9743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8793fbfac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxyRtmjs9OI5",
        "colab_type": "text"
      },
      "source": [
        "The system still mantains good accuracy. What about adding 50% dropout?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3l6JNob8exX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "a788fe2e-e48d-4de2-9963-faab08a1c50e"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model_dropout = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Dropout(0.5),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_dropout.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_dropout.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4326 - accuracy: 0.8683 - val_loss: 0.2364 - val_accuracy: 0.9310\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2858 - accuracy: 0.9143 - val_loss: 0.1831 - val_accuracy: 0.9484\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2495 - accuracy: 0.9247 - val_loss: 0.1552 - val_accuracy: 0.9539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8790deb550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqTswb7n-YLg",
        "colab_type": "text"
      },
      "source": [
        "Now let's try to change some of the network parameters, like strides, padding  and number of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clh8R27a-bt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "4fac86f9-49aa-4faf-e60c-82002587e254"
      },
      "source": [
        "num_filters = 5\n",
        "filter_size = 5\n",
        "\n",
        "model_new = Sequential([\n",
        "    Conv2D(num_filters, filter_size, input_shape=(28, 28, 1),\n",
        "    strides=2,\n",
        "    padding='same',\n",
        "    activation='relu',\n",
        "    ),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_new.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_new.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6206 - accuracy: 0.8248 - val_loss: 0.3025 - val_accuracy: 0.9119\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2718 - accuracy: 0.9187 - val_loss: 0.2262 - val_accuracy: 0.9333\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2181 - accuracy: 0.9347 - val_loss: 0.1990 - val_accuracy: 0.9399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8790b39550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfO-CJhlC55k",
        "colab_type": "text"
      },
      "source": [
        "Not much change, let's try to change the filter size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L392qm77BIR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "af08635f-5609-4927-a331-96c17941c304"
      },
      "source": [
        "num_filters = 5\n",
        "filter_size = 5\n",
        "\n",
        "model_new2 = Sequential([\n",
        "    Conv2D(num_filters, filter_size, input_shape=(28, 28, 1),\n",
        "    strides=2,\n",
        "    padding='same',\n",
        "    activation='relu',\n",
        "    ),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_new2.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_new2.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4332 - accuracy: 0.8806 - val_loss: 0.1866 - val_accuracy: 0.9435\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1760 - accuracy: 0.9477 - val_loss: 0.1431 - val_accuracy: 0.9572\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1447 - accuracy: 0.9572 - val_loss: 0.1248 - val_accuracy: 0.9594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f87909926d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKetW504D8Ay",
        "colab_type": "text"
      },
      "source": [
        "Finally, we will try all the changes together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVCeKn-AD7uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "1135ba89-0838-44c2-fb2b-2212877b796f"
      },
      "source": [
        "num_filters = 5\n",
        "filter_size = 5\n",
        "\n",
        "model_total = Sequential([\n",
        "    Conv2D(num_filters, filter_size, input_shape=(28, 28, 1),           \n",
        "    strides=2,\n",
        "    padding='same',\n",
        "    activation='relu',\n",
        "    ),\n",
        "    Conv2D(num_filters, filter_size),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Dropout(0.5),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_total.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model_total.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.5105 - accuracy: 0.8382 - val_loss: 0.1467 - val_accuracy: 0.9567\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2335 - accuracy: 0.9280 - val_loss: 0.1150 - val_accuracy: 0.9661\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2080 - accuracy: 0.9351 - val_loss: 0.0984 - val_accuracy: 0.9699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f878d07acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}